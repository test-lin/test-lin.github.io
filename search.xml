<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[罗马数字转整数]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2Froman-to-integer%2F</url>
    <content type="text"><![CDATA[题目罗马数字包含以下七种字符: I， V，X， L，C，D 和 M。 12345678字符 数值I 1V 5X 10L 50C 100D 500M 1000 例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。 27 写做 XXVII, 即为 XX + V + II 。 通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况： I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 给定一个罗马数字，将其转换成整数。输入确保在 1 到 3999 的范围内。 示例 1: 12输入: &quot;III&quot;输出: 3 示例 2: 12输入: &quot;IV&quot;输出: 4 示例 3: 12输入: &quot;IX&quot;输出: 9 示例 4: 123输入: &quot;LVIII&quot;输出: 58解释: L = 50, V= 5, III = 3. 示例 5: 123输入: &quot;MCMXCIV&quot;输出: 1994解释: M = 1000, CM = 900, XC = 90, IV = 4. 题目链接 提示 如果 I 在 V 或 X 之前, 减去 1 如: IV = 4 and IX = 9 如果 X 在 L 或 C 之前, 减去 10 如: XL = 40 and XC = 90 如果 C 在 D 或 M 之前, 减去 100 如: CD = 400 and CM = 900 标签 数学 字符串 个人解答1234567891011121314151617181920212223242526&lt;?phpfunction romanToInt($s) &#123; $map = [ 'I' =&gt; 1, 'V' =&gt; 5, 'X' =&gt; 10, 'L' =&gt; 50, 'C' =&gt; 100, 'D' =&gt; 500, 'M' =&gt; 1000 ]; $num = 0; $len = strlen($s); for ($i = 0; $i &lt; $len; $i++) &#123; if (($i &lt; $len - 1) &amp;&amp; ($map[$s&#123;$i&#125;] &lt; $map[$s&#123;$i+1&#125;]])) &#123; $num -= $map[$s&#123;$i&#125;]; &#125; else &#123; $num += $map[$s&#123;$i&#125;]; &#125; &#125; return $num;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis GEO 附近的连锁店]]></title>
    <url>%2F%E5%8A%9F%E8%83%BD%2Fredis-geo%2F</url>
    <content type="text"><![CDATA[说明reids 里自带的一个坐标定位方法。 使用123456789101112131415161718192021222324252627282930313233&lt;?php$redis = new Redis();$redis-&gt;connect("127.0.0.1", 6379);$redis-&gt;auth('you_password');$redis-&gt;select(3);// 添加坐标$key = '7-Eleven';list($x, $y) = [23.1194200000,113.4155300000];$region = "广州车坡分店";$redis-&gt;geoAdd($key, $x, $y, $region);// 更新坐标list($x, $y) = [25.1194200000,114.4155300000];$redis-&gt;geoAdd();// 删除坐标$redis-&gt;del($key);$redis-&gt;zRem($key, $region);// 店铺经纬度$redis-&gt;geoPos($key, $region);// 店铺与店铺之间的距离$redis-&gt;geoDist($key, $region, $region, 'km');// 附近的店$options = [ 'ASC'];$redis-&gt;geoRadius($key, -157.858, 21.306, 1, 'km', $options):]]></content>
      <categories>
        <category>功能</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>redis</tag>
        <tag>geo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What is HTTP/2?(什么是 HTTP/2？)]]></title>
    <url>%2F%E7%BF%BB%E8%AF%91%2Fwhat-is-http-2%2F</url>
    <content type="text"><![CDATA[Before diving straight into the topic, let’s first look at some of the HTTP/2 terminologies used frequently. 在深入讨论之前，让我们先看下经常使用的一些 HTTP/2 的术语。 Stream: An established bidirectional connection which may carry one or more messages Message: A complete sequence of frames that represents a request or response message Frame: The smallest unit of communication in HTTP/2. Each frame contains a frame header which could identify the stream to which the frame belongs. h2: Short term for HTTP/2 流: 已建立的双向连接，可以携带一个或多个消息 消息: 表示请求或响应消息的完整帧序列 帧: HTTP/2 中最小的通信单位。 每个帧包含一个帧头，它可以识别帧所属的流。 h2: HTTP/2 的短期 Note: It was originally named as HTTP/2.0 but later “.0” part was dropped because it has caused some confusions with HTTP/1.x. So we no longer use HTTP/2.0, it’s HTTP/2 or h2 for short 😊 注意: 它最初被命名为 HTTP/2.0，但后来“.0”部分被删除，因为它引起了 HTTP/1.x 的一些混淆。 所以我们不再使用 HTTP/2.0，简而言之是 HTTP/2 或 h2 Overview of HTTP/2HTTP/2 的概念HTTP/2 is a major revision of the HTTP network protocol which is still being widely used over the World Wide Web. It was developed to overcome some of the drawbacks found in HTTP/1.0 and HTTP/1.1 versions. Overhead of repetitive headers and Head-of-line blocking (HOL blocking — when one request is blocking others from completing) are two such major problems addressed. HTTP/2 是 HTTP 网络协议的主要修订版，它仍在万维网上广泛使用。 它的开发是为了克服 HTTP/1.0 和 HTTP/1.1 版本中的一些缺点。 重复标题和 行头阻塞 的开销（HOL 阻止 - 当一个请求阻止其他人完成时）是两个这样的主要问题。 HTTP/2 enables more efficient use of network resources, header fields compression, multiple concurrent exchanges on the same connection reducing the latency to a great extent. HTTP/2 可以更有效地使用网络资源，头字段压缩，同一连接上的多个并发交换，在很大程度上减少了延迟。 HTTP/2 also introduces Server Push that allows a server to send desired data to a client that the server anticipates the client will need in the future. Thus, HTTP/2 provides enhanced security, speed, and usability. HTTP/2 还引入了 服务器推送，允许服务器将所需数据发送到服务器预期客户端将来需要的客户端。 因此，HTTP/2 提供增强的安全性，速度和可用性。 HTTP/2 uses the same URI scheme and shares the same default HTTP ports as of HTTP/1.1. HTTP/2 使用相同的 URI 方案，并共享与 HTTP/1.1 相同的默认 HTTP 端口。 All communication is performed over a single TCP connection that can carry any number of bidirectional streams. Each stream has a unique identifier and optional priority information that is used to carry bidirectional messages. The frame is the unit of communication and there are several types of frames such as HEADER, DATA, and SETTINGS. For request and response communication, HEADER and DATA frames are primarily being used. 所有通信都通过单个 TCP 连接执行，该连接可以承载任意数量的 双向流。每个流都有唯一的标识符和可选的优先级信息，用于携带双向消息。帧是通信单元，有几种类型的帧，如 HEADER、DATA 和 SETTINGS。 对于请求和响应通信，主要使用 HEADER 和 DATA 帧。 Key benefits of HTTP/2HTTP/2 的主要优点MultiplexingUnlike in HTTP/1.1 where each transfer has to wait till other transfers complete, in HTTP/2, multiple requests are allowed at the same time on the same connection. 与 HTTP/1.1 中的情况不同，其中每个传输必须等到其他传输完成，在 HTTP/2 中，在同一连接上同时允许多个请求。 In HTTP/1.x, only one response can be delivered at a time per connection, and if the client wants to make multiple parallel requests, then multiple TCP connections must be used. This also results in head-of-line-blocking and inefficient use of underlying TCP connection. 在 HTTP/1.x 中，每个连接一次只能传递一个响应，如果客户端想要进行多个并行请求，则必须使用多个 TCP 连接。 这也会导致线头阻塞和底层 TCP 连接的低效使用。 HTTP/2 overcomes these limitations by using the new binary framing layer ( where all HTTP/2 communication is split into smaller messages and frames and each of them is encoded in binary format so that both the client and server must use the new binary encoding mechanism in order to understand each other. Thus, an HTTP/1.x client will not understand an HTTP/2 only server and vice versa. ) by allowing the client and server to break down a message into independent frames, interleave them and reassemble them on the other end. HTTP/2 通过使用新的二进制成帧层克服了这些限制（其中所有 HTTP/2 通信被分成更小的消息和帧，并且每个都以二进制格式编码，因此客户端和服务器都必须使用新的二进制编码机制因此，HTTP/1.x 客户端将无法理解仅 HTTP/2 服务器，反之亦然。）允许客户端和服务器将消息分解为独立的帧，交错并重新组合它们在另一端。 For example, 例如， The above diagram illustrates multiple streams within the same connection. The client is transmitting a DATA frame over stream 5 to the server, while the server is transmitting an interleaved sequence of frames to the client over stream 1 and 3. 上图说明了同一连接中的多个流。 客户端通过流 5 将 DATA 帧发送到服务器，而服务器通过流 1 和 3 将交错的帧序列发送到客户端。 This also enables several performance benefits such as remove unnecessary HTTP/1/x workarounds in concatenated files, image sprites and domain sharding ( for further read refer: Optimizing for HTTP/1.x ), reduce the page load time by removing unnecessary latency and improving the utilization of available network capacity. 这还可以带来一些性能优势，例如在连接文件，图像精灵和域分片中删除不必要的 HTTP/1/x 变通方法（ 有关进一步阅读，请参阅： 优化 HTTP/1.x），通过消除不必要的延迟并提高可用网络容量的利用率来减少页面加载时间。 Header compression标头压缩As web pages have grown to require dozens to hundreds of requests, the redundant header fields in these requests unnecessarily consume bandwidth, measurably increasing latency. So, HTTP/2 forces all HTTP headers to be sent in a compressed format, reducing the amount of information that needs to be exchanged between the client’s browser and the server whereas HTTP/1.1 does not provide any form of header compression. 随着网页变得需要数十到数百个请求，这些请求中的冗余头字段不必要地消耗带宽，可测量地增加了延迟。 因此，HTTP/2 强制所有 HTTP 标头以压缩格式发送，减少了客户端浏览器和服务器之间需要交换的信息量，而 HTTP/1.1 不提供任何形式的标头压缩。 The compression works on per connection basis. That is, all the streams in one connection share the same compressor. If the compressor realizes that it has sent a header before, it will not resend that header, instead just says ‘the same header as before’. So, some headers that never change like Host, Accept or Cookies will not get resent, and that will save a lot of bytes! 😃 压缩适用于每个连接。也就是说，一个连接中的所有流共享相同的压缩器。如果压缩器意识到它之前已经发送了一个报头，它将不会重新发送该报头，而只是说“与之前相同的报头”。 因此，一些永远不会像 Host、Accept 或 Cookies 那样改变的标题将不会被重新发送，这将节省大量的字节！ Server Push服务器推送Through the server push, additional resources can be sent to the client for future use, before the client even requests them. 通过服务器推送，可以在客户端甚至请求之前将其他资源发送到客户端以供将来使用。 Here, the server understands which resources the browser needs before the browser requests for them. Then the server will push these resources to the browser before it requests for them. This makes the entire process of retrieving all resources much faster. 在这里，服务器了解浏览器在浏览器请求之前需要哪些资源。 然后，服务器会在请求它们之前将这些资源推送到浏览器。 这使得检索所有资源的整个过程更快。 As an example when a browser requests a web page, a server responds with an HTML page and browser has to parse it and request again all embedded assets such as images, CSS and JavaScript files. In HTTP/2, using the server push concept a server can be configured to send all required assets according to a client’s request before the client requests them explicitly. 作为浏览器请求网页的示例，服务器响应 HTML 页面，浏览器必须解析它并再次请求所有嵌入的资源，例如图像，CSS 和 JavaScript 文件。 在 HTTP/2 中，使用服务器推送概念，可以将服务器配置为在客户端明确请求之前根据客户端的请求发送所有必需的资产。 Stream Priority流的优先级While multiplexing enables sending multiple requests concurrently, stream priority enables you to define which response should come first. I.e. it helps you to define the importance of one stream relative to the other streams on the same connection via weight and dependency associated with each stream. As a result, we can optimize the resource usage via controlling the allocation of CPU, memory, bandwidth and many other resources while ensuring the delivery of high priority responses to the client. 虽然多路复用可以同时发送多个请求，但流优先级使您可以定义应该首先响应的响应。 也就是说，它可以帮助您通过与每个流关联的权重和依赖关系来定义一个流相对于同一连接上的其他流的重要性。 因此，我们可以通过控制 CPU，内存，带宽和许多其他资源的分配来优化资源使用，同时确保向客户端传递高优先级响应。 Flow control流量控制This is introduced to prevent any destructive interference on streams with each other that are in the same connection that might have caused as a result of multiplexing which introduces contention over use of the TCP connection causing blocked streams. Flow control is used for both individual streams and for the connection as a whole. 引入这是为了防止对由于多路复用而可能导致的相同连接的流相互之间的任何破坏性干扰，这引起了对使用 TCP 连接导致阻塞流的争用。 流量控制用于单个流和整个连接。 Error handling错误处理HTTP/2 handles two classes of errors. HTTP/2 处理两类错误 Connection error — any error that prevents further processing of the frame layer or corrupts any connection state. Stream error — an error related to a specific stream that does not affect the processing of other streams. 连接错误 — 任何阻止进一步处理帧层或破坏任何连接状态的错误。 流错误 — 与特定流相关的错误，不会影响其他流的处理。 I will be talking on How to Write an HTTP/2 Service and a Client in my next story 😊 我将在下一个故事中讨论如何编写 HTTP/2 服务和客户端😊 Mar 11,2019 （2019-03-11） author: Varuni Punchihewa link: https://blog.usejournal.com/what-is-http-2-380d277d208c]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[表状态程序管理应用]]></title>
    <url>%2F%E5%8A%9F%E8%83%BD%2Ftable-status%2F</url>
    <content type="text"><![CDATA[说明表的状态是我们判断业务到达什么地方的标识，它可以是英文单词，也可以是数字，更可以是枚举。在开发的过程中，有人是直接写状态值，这样很不好维护，如果值变更，他就得把程序里关联的值全部都需要修改。 处理model 常量model 对应的是数据表来创建的。所以表中的状态字段可以使用常量来表示，使用时直接使用常量访问即可。 12345678910111213&lt;?phpclass OrderModel extends Model&#123; const STATUS_TO_AUDIT = 2; const STATUS_TO_DELIVER = 3; public function getList($where) &#123; $map = []; $map['status'] = self::STATUS_TO_AUDIT; &#125;&#125; model 静态属性静态属性主要的作用是搜索下拉表单（需要格式化处理）和列表状态显示时使用。 123456789101112&lt;?phpclass OrderModel extends Model&#123; const STATUS_TO_AUDIT = 2; const STATUS_TO_DELIVER = 3; public static $status = [ self::STATUS_TO_AUDIT =&gt; '待审核', self::STATUS_TO_DELIVER =&gt; '待发货', ];&#125; 混合状态管理混合状态就是表示一种业务状态，需要几个状态字段进行判断才可以确认业务的实际状态。这种混合状态是很不好维护的，因为你在开发中会发现你总是漏改某些字段被挨批。管理这种状态的办法就是把实际状态用数组存储起来。 1234567891011121314151617181920212223242526272829303132333435363738&lt;?phpclass OrderModel extends Model&#123; // 订单状态 const STATUS_TO_AUDIT = 2; const STATUS_TO_DELIVER = 3; const STATUS_SUCCESS = 4; // 售后状态 const RETURN_NOT = 0; const RETURN_TODO = 1; const RETURN_ACCESS = 2; const RETURN_FAIL = 3; // 无售后订单 private $orderSuccess = [ 'status' =&gt; self::STATUS_SUCCESS, 'return_status' =&gt; self::RETURN_NOT, ]; // 售后失败订单 private $orderReturnFail = [ 'status' =&gt; self::STATUS_SUCCESS, 'return_status' =&gt; self::RETURN_FAIL, ]; // 变更表状态,使用类覆盖 // $data += $this-&gt;orderReturnFail; // 验证订单状态 // foreach ($this-&gt;orderReturnFail as $key =&gt; $value) &#123; // if ($data[$key] != $value) &#123; // return false; // &#125; // &#125; // return true;&#125; FQA验证当前操作的状态值是否合法12345&lt;?phpif (!in_array($status, array_keys(OrderModel::$statusMap)) &#123; // 非法状态值&#125; 表里的状态值很多，但是显示给用户只需要其中几个123456789101112&lt;?phpclass OrderController&#123; public function getOrderStatus() &#123; return [ OrderModel::STATUS_TO_AUDIT =&gt; OrderModel::$statusMap[OrderModel::STATUS_TO_AUDIT], OrderModel::STATUS_SUCCESS =&gt; OrderModel::$statusMap[OrderModel::STATUS_SUCCESS], ]; &#125;&#125;]]></content>
      <categories>
        <category>功能</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Internet changes: HTTP/3 will not use TCP anymore(因特网变更：HTTP/3 将不再使用 TCP)]]></title>
    <url>%2F%E7%BF%BB%E8%AF%91%2Fthe-internet-changes-http-3-will-not-use-tcp-anymore%2F</url>
    <content type="text"><![CDATA[QUIC is the protocol underlying the next version of HTTPQUIC 是下一个版本 HTTP 的基础协议the Internet Engineering Task Force (IETF) has revealed that the third official version of HyperText Transfer Protocol (HTTP) will not use TCP anymore. Instead, it will run over the QUIC protocol first developed by Google back in 2012. 因特网工程工作组（Internet Engineering Task Force 简称：IETF）透露，第三个官方版本的超文本传输协议（HyperText Transfer Protocol 简称：HTTP）将不再使用 TCP。反而，它将运行 2012 年由谷歌首次开发的 QUIC 协议。 WHAT IS QUIC?什么是 QUIC？Quick UDP Internet Connections (QUIC) is, as its name states, a transport layer protocol based on multiplexed UDP connections. In fact, QUIC uses a combination of TCP + TLS + SPDY over UDP with several enhancements with respect to the current HTTP/2 over TCP implementation. 快速 UDP 因特网连接（Quick UDP Internet Connections 简称：QUIC） 是一种基于多路复用的 UDP 连接的传输层协议。事实上，QUIC 使用了 TCP + TLS + SPDY over UDP 与当前 HTTP/2 over TCP 实现的几个增强功能的组合。 The IETF has been working on a standardized version of Google’s QUIC since 2016, and it was recently that they announced their intention to include it for the new HTTP/3 version. However, the IETF QUIC version already diverged significantly from the original QUIC design. IETF 自 2016 年以来一直致力于开发标准化的 Google QUIC 版本，最近他们宣布打算将其用于新的 HTTP/3 版本。然而，IETF 的 QUIC 版本已经与原来的 QUIC 设计有了很大的不同。 Position of HTTP/3 and QUIC in the protocol stackHTTP/3 和 QUIC 在协议栈中的位置 QUIC protocol aims for simplicity and speed while maintaining security thanks to the TLS 1.3 encryption. They developed a more efficient protocol in terms of connection establishment and data transfer. According to Google, QUIC handshakes frequently require zero roundtrips before sending payload, as compared to 1–3 roundtrips for TCP+TLS. Actually, the first connection ever requires one roundtrip and the followings will work with zero. 由于采用了 TLS 1.3 加密，QUIC 协议旨在简化和提高速度，同时保持安全性。他们在建立连接和数据传输方面开发了一种更有效的协议。据谷歌称，与 TCP + TLS 的 1-3 次往返相比，Quic握手在发送有效负载之前通常需要0次往返。实际上，第一次连接需要一次往返，下面的内容将不往返。 Furthermore, it deals better with packet loss than the current TCP. Every retransmitted packet consumes a new sequence number, hence eliminating ambiguities and preventing losses from causing RTO. As Jana Iyengar from IETF states, QUIC is not only a redefinition of the Internet transport layer but a reinvention to do the transport right. 此外，它比当前的 TCP 更能处理数据包丢失。每一个重新传输的包都会消耗一个新的序列号，因此消除了模糊性，并防止了造成 RTO 的损失。正如来自 IETF 的 Jana Iyengar 所说，QUIC 不仅是对互联网传输层的重新定义，而且是对实现传输权的重新定义。 At the moment, only 1.2 % of the top websites support QUIC, but they are generally high-traffic sites: almost every Google service supports their own QUIC protocol. 目前，只有 1.2% 的顶级网站支持 QUIC，但它们通常是高流量的网站：几乎每个谷歌服务都支持自己的 QUIC 协议。 IS QUIC SECURE?QUIC 是安全的？QUIC first development included its own encryption. However, it was just a temporary implementation destined to be replaced by TLS 1.3 as described by the IETF. QUIC 的第一个开发包括它自己的加密。然而，正如 IETF 所描述的，它只是一个临时的实现，注定要被 TLS 1.3 所取代。 Actually, the connection establishment strategy of QUIC is based on the combination of crypto and transport handshake. 实际上，QUIC 的连接建立策略是基于加密和传输握手的结合。 QUIC relies on a combined cryptographic and transport handshake to minimize connection establishment latency. QUIC 依赖于密码和传输握手的组合，以最小化连接建立延迟。 Integration of QUIC and TLS, adapted from the IETF’s draft of “Using Transport Layer Security (TLS) to Secure QUIC”.QUIC 和 TLS 的集成，改编自 IETF 的 “使用传输层安全性（Transport Layer Security 简称：TLS）保护 QUIC” 草案。 With QUIC, Everything will be encrypted by default. Nevertheless, there are indeed security risks with QUIC as with any other technology. 使用 QUIC，默认情况下将加密所有内容。然而，与其他技术一样，QUIC 确实存在安全风险。 The work of Robert Lychev and Samuel Jero in 2015 reported several weaknesses of the protocol. QUIC performance can be degraded by attacks like the Server Config Replay Attack. However, the confidentiality and the authenticity of the data seem to be properly secured according to their security model and tests. Robert Lychev 和 Samuel Jero 在 2015 年的研究报告了该协议的几个弱点。像服务器配置重放攻击这样的攻击会降低 QUIC 性能。然而，根据安全模型和测试，数据的机密性和真实性似乎得到了适当的保护。 Understanding Event-Driven Architectures (EDA): the paradigm of the future 理解事件驱动的architectures（EDA）：“范式” BITCOIN case study: applying basic Digital Signal Processing into financial data BITCOIN 案例研究：将基本数字信号处理应用于金融数据 If you want to learn more about QUIC and how it will be integrated into the next version of HTTP, I strongly recommend you to check the official documentation from Google and the drafts published by IETF. You can find them in the bibliography of this article! 如果您想了解更多关于 QUIC 的信息，以及如何将其集成到下一个 HTTP 版本中，我强烈建议您查看来自 Google 的官方文档和 IETF 发布的草稿。你可以在这篇文章的参考书目中找到它们！ Innovation is always spinning forward. Just like a Drill. 创新总是向前旋转。就像一个练习。 BIBLIOGRAPHY参考文献[1] ”QUIC, a multiplexed stream transport over UDP — The Chromium Projects”, Chromium.org. [Online]. Available: https://www.chromium.org/quic. [Accessed: 18- Nov- 2018] [2] M. Thomson, “draft-ietf-quic-transport-16 — QUIC: A UDP-Based Multiplexed and Secure Transport”, Tools.ietf.org, 2018. [Online]. Available: https://tools.ietf.org/html/draft-ietf-quic-transport-16. [Accessed: 18- Nov- 2018] [3] S. Turner, “draft-ietf-quic-tls-03 — Using Transport Layer Security (TLS) to Secure QUIC”, Tools.ietf.org, 2018. [Online]. Available: https://tools.ietf.org/html/draft-ietf-quic-tls-03#section-3. [Accessed: 18- Nov- 2018] [4] E. Rescorla, “The Transport Layer Security (TLS) Protocol Version 1.3”, Tools.ietf.org, 2018. [Online]. Available: https://tools.ietf.org/id/draft-ietf-tls-tls13-23.html. [Accessed: 18- Nov- 2018] [5] R. Lychev, S. Jero, A. Boldyreva and C. Nita-Rotaru, “How Secure and Quick is QUIC? Provable Security and Performance Analyses”, 2015. [Online]. Available: https://www.cc.gatech.edu/~aboldyre/papers/quic.pdf. [Accessed: 18- Nov- 2018] Nov 18, 2018 （2018-11-18） author: Telmo Subira Rodriguez link: https://medium.com/drill/the-internet-changes-http-3-will-not-use-tcp-anymore-427e82eeadc0]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回想自己第一次写爬虫的经历]]></title>
    <url>%2F%E5%9B%9E%E5%BF%86%E5%BD%95%2F%E5%9B%9E%E6%83%B3%E8%87%AA%E5%B7%B1%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%86%99%E7%88%AC%E8%99%AB%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[起因第一次爬虫是因为觉得上班不忙，又不想每天玩游戏让自己后悔。所以以锻炼为目的写爬虫。因为自己尿性是没有毅力也很容易放弃的人。所以我选择的内容是抓小网站，让自己的学习不会太过于困难。那时并没有很多开发经验，也没有做所谓的启动准备。都是想到什么就去做什么，也不知道自己这个项目要做到什么程度。 实现经过我的想法很简单，取得网页，匹配网页想要的内容并保存起来。因为技能问题，我没有使用 python 来抓取。我用的是 php。 最开始，我使用 file_get_content() 函数来取得网页，然后用正则匹配来匹配内容，但是那太慢了，然后我就去搜了一下，使用了 curl 函数来代替了 file_get_content。 我抓取的网站有三种内容：文章、图组和视频 文章只需要抓取网页就可以取得内容了。但是图组不但要取得网页，还要匹配到的图片下载到本地中。当时完全就是写一个脚本文件，然后就执行。所以我分成两步脚本进行处理。但是总是被大大小小的问题卡往。后面也只做了文章和图组的抓取，也没有整理维护了。 碰到的问题字符编码因为有些文章并不是使用 utf-8 编码，所以我们需要通过 mb_detect_encoding 函数检查网页的字符编码并用 iconv 函数转成 utf-8 的格式。 内存占用越过了 php.ini 的限制，导致报异常程序中断最开始我的想法是把所有得到的内容先存放在变量中，到结束后再进行一些性保存，所以导致变量存了太多数据 资源重复编码时没有考虑到脚本中断的情况，每次都是从头开始。还有一些图组资源是本来就是重复的， 脚本运行卡死下载时有网络波动、电脑休眠都会导致卡死。这种情况要么就想办法处理网络波动和电脑的问题，要么就做一些中断命令后重新运行会接着执行的操作。 数据丢失文章内容存在数据库，使用的是 text 类型字段，但是抓取的内容超过了范围导致内容遗失。可以有以下 2 种办法去解决这种问题。 设置合适的字段 切换一种内容存储方式，如存成文件 扩展思考模拟登录这里涉及到 session 原理。传统的网站一般都使用 session 原理来实现登录绑定。所以我们只需要把登录成功后的所有 cookie 带上，并允许 cookie 改变即可。 curl 可以进行设置 定时抓取使用定时任务，并把上面说的可持续查询方法使用上即可。 反反爬虫有爬虫自然就会有反爬虫的机制。有的使用单一的一种机制来防止，有的又是使用混合的机制来进行制约。不管什么方式都有越过方法。主要反爬虫有：301中转、混乱的字符编码、不成对 html 标签以及请求速率限制。]]></content>
      <categories>
        <category>回忆录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[登录失败次数限制]]></title>
    <url>%2F%E5%8A%9F%E8%83%BD%2Flogin-limit%2F</url>
    <content type="text"><![CDATA[说明这是一个防频繁请求登录接口导致服务器性能占用过多。也可以防止别人尝试密码 原理记录用户访问次数，到指定次数后对他进行锁处理。实现方法很简单，前端使用 cookie 进行请求记录，请求成功会把登录次数相关的 cookie 清理掉。接口端也需要一起进行记录防止直接对接口进行请求。接口端使用 redis 记录他的 IP，又用别一个键来判别锁状态。 实现12345678910111213141516171819202122232425262728293031323334&lt;?php$redis = new Redis();$redis-&gt;connect("127.0.0.1", 6379);$redis-&gt;auth('you_password');$redis-&gt;select(3);$ip = get_client_ip();if ($redis-&gt;get("login_lock.&#123;$ip&#125;")) &#123; // 禁止访问接口&#125;// 添加访问次数$redis-&gt;incr("login_count.&#123;$ip&#125;");// 上锁$addLockCount = 3;if ($addLockCount &lt; $redis-&gt;get("login_count.&#123;$ip&#125;")) &#123; // 锁定次数 $redis-&gt;incr("login_lock_count.&#123;$ip&#125;"); // 锁定次数越多，锁定时间越长 $lockTime = 60 * $redis-&gt;get("login_lock_count.&#123;$ip&#125;"); $redis-&gt;set("login_lock.&#123;$ip&#125;", $ip, $lockTime); // 清空登录记录数 $redis-&gt;del("login_count.&#123;$ip&#125;");&#125;// 登录成功要记得去除关联的缓存$redis-&gt;del("login_count.&#123;$ip&#125;");$redis-&gt;del("login_lock.&#123;$ip&#125;");$redis-&gt;del("login_lock_count.&#123;$ip&#125;");]]></content>
      <categories>
        <category>功能</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回文数]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2Fpalindrome-number%2F</url>
    <content type="text"><![CDATA[题目判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 示例 1: 12输入: 121输出: true 示例 2: 123输入: -121输出: false解释: 从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。 示例 3: 123输入: 10输出: false解释: 从右向左读, 为 01 。因此它不是一个回文数。 进阶: 你能不将整数转为字符串来解决这个问题吗？ 题目链接 注： 反转回文时需注意数值溢出 标签 数学 个人解答如题可知单数，负数，0结尾的整数都不是回文数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 方法1 前后数字对比function isPalindrome($x) &#123; if ($x &lt; 9 || ($x % 10 === 0)) return false; $x = (string)$x; $i = 0; $max = strlen($x) - 1; while ($i &lt; $max) &#123; if ($x&#123;$i&#125; == $x&#123;$max&#125;) &#123; $i++; $max--; &#125; else &#123; return false; &#125; &#125; return true;&#125;# 方法2 翻转数字对比function isPalindrome($x) &#123; if ($x &lt; 9 || ($x % 10 === 0)) return false; $rev_num = 0; $val = $x; while ($val != 0) &#123; // 注：凡是数字反转都可能会存在数字值越范围的情况 $rev_num = bcmul($rev_num, 10) + ($val % 10);// ($rev_num * 10) + ($val % 10) $val = bcdiv($val, 10); // $val / 10; &#125; return ($rev_num === $x);&#125;# 方法3 数字法前后对比function isPalindrome($x) &#123; if ($x &lt; 9 || ($x % 10 === 0)) return false; // 取 $x 的位数 $bit = 1; while (9 &lt; bcdiv($x, $bit)) &#123; // 除出来的数大于 9 就要进位 $bit = $bit * 10; &#125; while (9 &lt; $x) &#123; // 除下的数如果大于 9 就还可以进行对比，如 10 的 10，个位数就不用比了 $l = bcdiv($x, $bit); // $x / $bit $r = $x % 10; if ($l != $r) return false; $x = $x % $bit; // 去头 $x = bcdiv($x, 10); // 去尾 $x / 10 $bit = bcdiv($bit, 100); // $bit / 100 = 头+尾 = 10 * 10 &#125; return true;&#125; 做题总结这到题加深了上周做的整数反转所使用的循环技巧。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何减少需求理解的偏差]]></title>
    <url>%2F%E6%80%9D%E8%80%83%2F%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E9%9C%80%E6%B1%82%E7%90%86%E8%A7%A3%E7%9A%84%E5%81%8F%E5%B7%AE%2F</url>
    <content type="text"><![CDATA[工作中，我们总是会因为种种原因导致自己做的功能不合格需要重做。那么如何减少需要理解的偏差呢？ 思考为什么总想着做一步想一步呢很多时候我们接到任务总是忍不了自己内心的冲动，上去就是干。要么开发到一半因为一个功能细节整个程序的设计都不合理要重构，要么完成后，改了 N 次都还是没有被判断任务完成。如果我们接到任务时把功能的每个细节都过一遍。把不明白的地方问产品问清楚，那后面开发完后就只会是需求修改的那种修改了，这就不是自身的问题了。 为什么同一个原型别人理解的功能和我理解的不同就像莎士比亚说的：“一千个读者就有一千个哈姆雷特”，每个人理解方面都会有偏差。最好的状态就是所以功能开发的原因都了解清楚。要不然做一个连你自己都觉得没用的功能，后面砍掉了你也无处讲理去。而实现的细节我们可以向产品以及组长校对自己的理解。才会最大限度的减少误差。 结论不管在工作中还是在平时生活中，我们应该深入做事的原因。如果是帮忙，需要完全确认自己的理解是否偏差，开发的细节是否有遗漏。沟通的成本确实是很大。但是动脑动嘴比动手来的轻松很多。]]></content>
      <categories>
        <category>思考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis unauthorized access vulnerability simulation(redis未经授权的访问漏洞模拟)]]></title>
    <url>%2F%E7%BF%BB%E8%AF%91%2Fredis-unauthorized-access-vulnerability-simulation%2F</url>
    <content type="text"><![CDATA[Redis, is an open source, widely popular data structure tool that can be used as an in-memory distributed database, message broker or cache. Since it is designed to be accessed inside trusted environments, it should not be exposed on the Internet. However, some Redis’ are bind to public interface and even has no password authentication protection. Redis是一个开源的、广泛流行的数据结构工具，可以用作内存中的分布式数据库、消息代理或缓存。因为它被设计为在受信任的环境中访问，所以不应该在 Internet 上公开。然而，一些 Redis 绑定到公共接口，甚至没有密码身份验证保护。 Under certain conditions, if Redis runs with the root account (or not even), attackers can write an SSH public key file to the root account, directly logging on to the victim server through SSH. This may allow hackers to gain server privileges, delete or steal data, or even lead to an encryption extortion, critically endangering normal business services. 在某些条件下，如果Redis使用 root 帐户运行（甚至不使用），攻击者可以向根帐户写入 SSH 公钥文件，直接通过 SSH 登录到受害服务器。这可能使黑客获得服务器特权，删除或窃取数据，甚至导致加密勒索，严重危害正常的业务服务。 The simplified flow of this exploit is: Login to a unprotected Redis Change it’s backup location to .ssh directory — Write the SSH Keys to new backup location Remote connect and login to the target server using SSH key We should already be familiar how automatic SSH login with private + public keys works. 简化实现流程如下： 登录到一个无保护的 Redis 将备份位置更改为 .ssh 目录 —— 将SSH密钥写入新的备份位置 使用 SSH 密钥远程连接并登录到目标服务器 我们应该已经熟悉了如何使用私有+公钥自动登录 SSH。 Simulation模拟Now let’s get our feet wet and set up a target machine. We’ll need two machines, they can be real machines, virtual machines, or remote machines (VPS). As long as the attack end is able to ping the target end, we are good. 现在让我们先把做好模拟前准备。我们需要两台机器，它们可以是真正的机器、虚拟机或远程机器(VPS)。只要攻击端能够 ping 目标端就可以了。 Environment setup for this example: Target Machine: Redis-3.2.11 on Ubuntu Attack Machine: Platform you like with Redis (I used Kali) 示例中的环境如下： 目标机器：ubuntu 下有 Redis-3.2.11 攻击机器：你喜欢的平台与 Redis(我用的是 Kali) Set Up Target Machine:设定目标机器：First, let us set up the target machine with Redis. Download source code by 首先，让我们配置目标机器的 Reids。下载源代码 1wget http://download.redis.io/releases/redis-3.2.11.tar.gz Extract and build 提取和构建 12tar xzf redis-3.2.11.tar.gz cd redis-3.2.11make After make, we use our favorite editor to open redis.conf in redis-3.2.11 folder. In order to be remotely accessed, we will need to comment out line bind 127.0.0.1 and disable protected-mode as shown below. 编译后，我们使用我们最喜欢的编辑器打开 redis-3.2.11 文件夹 的 redis.conf。为了远程访问，我们需要注释掉 bind 127.0.0.1 行，并禁用 protected-mode，如下所示。 Now fire up Redis with the configuration file we just edited. Note that redis-server is in redis-3.2.11/src. 现在用我们刚刚编辑的配置文件启动Redis。注意 redis-server 在 redis-3.2.11/src 中。 1src/redis-server redis.conf So far, we have finished setting up the target server. Additionally, we should also check if we have .ssh folder. If not, we should create it for the attack later. 到目前为止，我们已经完成了目标服务器的设置。此外，我们还应该检查我们是否有 .ssh的文件夹。如果没有，我们应该为以后的攻击创建它。 Attack Machine:攻击机器：First, make sure we can ping the target. Then, we will generate a private key and public key for SSHing into the target machine later. Run the following command to generate SSH keys and leave passphrase empty. 首先，确保我们能锁定目标。然后，我们将生成私钥和公钥，以便稍后将其插入目标机器。运行以下命令生成SSH密钥，并保留密码为空。 1ssh-keygen -t rsa Next, enter the .ssh folder. If you are root user, enter /.ssh, otherwise ~/.ssh, then copy the private key in to temp.txt. 下一步，进入 .ssh 目录。如果你是 root 用户，进入 /.ssh，其他的进入 ~/.ssh。复制私钥到 temp.txt。 1(echo -e &quot;\n\n&quot;; cat id_rsa.pub; echo -e &quot;\n\n&quot;) &gt; temp.txt Some may be wondering that why do we put two blank lines before and after the public key? We will leave that as a mystery for right now if you don’t know :) 有些人可能想知道，为什么在公钥之前和之后要放两行空白?如果你不知道，我们暂时把它作为一个谜 :) Good! So far we have generated a pair a keys, we will need to find a way to smuggle the public key to the Redis server (target machine.) 好了！到目前为止，我们已经生成了一对密钥，我们将需要找到一种方法将公钥偷运到Redis服务器(目标机器)。 We are going to use redis-cli, the Redis command line interface, to send commands to Redis and read the replies sent by the server directly in the terminal. 我们将使用 redis-cli，即 Redis 命令行接口，向 Redis 发送命令，并直接读取终端服务器发送的响应。 Run the following commands in redis-3.2.11/src folder. (Or depending where we are, we can always specify the path to the files we use) 在 redis-3.2.11/src 文件夹中运行以下命令。(或者根据我们的位置，我们总是可以指定我们使用的文件的路径) 1cat /.ssh/temp.txt | redis-cli -h 203.137.255.255 -x set s-key Here, let’s take a look at the command. We use -h flag to specify the remote Redis server IP so that redis-cli knows where to connect and send commands. The part after -x is saying that we are setting the key in redis named s-key with the value in temp.txt. 在这里，让我们看一下命令。我们使用 -h 标志来指定远程 Redis 服务器 IP，以便 redis-cli 知道在何处连接和发送命令。-x 后面的部分表示，我们正在设置 redis 中的键名为 s-key，其值位于 temp.txt 中。 Yea, we have a key with our SSH key sneaked in! Let’s connect to the Redis and play around its configuration. Use redis-cli to connect to the Redis server again. 是的，我们有一个密钥，SSH 密钥偷偷溜进来了!让我们连接到Redis并研究它的配置。再次使用 redis-cli 连接到 Redis 服务器。 Looking at the above screenshot, we first verify the value of the key s-key by using the command GET s-key, which is what we want – the public key with two blank lines before and after. Then I tried the command “dir” just to see what it says (kidding). What we actually want to do here is to get the value of “s-key” (SSH public key) stored in the .ssh folder so that we can remote SSH login to the target machine whithout having to type the password. 查看上面的屏幕截图，我们首先使用命令 GET s-key 来验证键 s-key 的值，这正是我们想要的——前后各有两行空白的公钥。然后，我尝试命令 “dir”，只是为了看看它说了什么(开玩笑)。这里我们真正想做的是获取存储在 .ssh 文件夹中的“s-key”(SSH公钥)的值，这样我们就可以远程ssh登录到目标机器，而不需要输入密码。 Thus, we will do this: 因此，我们将这样做: 123456CONFIG GET dir # get your redis directory# In the output of above command &quot;/home/xxxx/redis-3.2.11/src&quot; is the directory where redis server is installed. CONFIG SET dir/home/xxxx/.ssh # set the backup location to the .ssh folder(or) CONFIG SET dir /root/.ssh CONFIG SET dbfilename authorized_keys# lastly we back our data containing our &quot;s-key&quot; key-value pair up in the .ssh foldersave The authorized_keys file in SSH specifies the SSH keys that can be used for logging into the user account for which the file is configured Source: ssh.comThe screenshot shown above already demonstrates the steps mentioned here. SSH中的 authorized_keys 文件指定了 SSH 密钥，可用于登录到文件配置源的用户帐户: ssh.com上面的截图已经演示了这里提到的步骤。 Harvest Time结果时间On Attack Machine, try to SSH in the Target Machine using the following command. 在攻击机器上，尝试使用下面的命令在目标机器上SSH。 12# command: private key username@server IPssh -i id_rsa username@203.137.255.255 YAS! As we can see, we have a successful auto-login with SSH keys! Voila, we have now completed the attack simulation. 😃 好，可以看到，我们成功地使用 SSH 密钥自动登录!瞧，我们现在已经完成了攻击模拟。😃 (Smiley face actually means that I’m finally almost done writing this up 😂) (笑脸实际上意味着我差不多写完了😂) At the end of this section, I would like to show what is Redis’s backup file look like. 在本节的最后，我想展示一下什么是 Redis 的备份文件。 Notice the unreadable characters? Add “\n\n” before and after the key content was just to be safe and separate it from other “stuff” so that it can be parsed correctly. 👌 注意到这些不可读的字符了吗?在关键内容之前和之后添加“\n\n”只是为了安全起见，并将其与其他“内容”分开，以便正确解析。 Use Search Engine to find Vulnerable Redis Servers使用搜索引擎查找易受攻击的Redis服务器Alrighty, as I mentioned, we are going to use Shodan to search servers that has Redis footprint (characteristics). 好的，正如我提到的，我们将使用 Shodan 来搜索具有 Redis footprint(特征)的服务器。 Let us do a simple search by Redis’ default port. 让我们做一个简单的搜索，通过Redis的默认端口。 Looks like we have 75,665 search results. Aaaaaand guess what! Right down there (not shown but we can see it if we scroll down) there are TONS of host that has NO password protection!! 看起来我们有 75,665 个搜索结果。猜猜看!就在那里(没有显示，但我们可以看到，如果我们向下滚动)有些主机没有密码保护!! This vulnerability was found years ago and still countless of machines are opening up themselves in such an easy way for attackers to have fun in there server… 这个漏洞是几年前发现的，仍然有无数的机器以这种简单的方式打开自己，让攻击者在那里的服务器中得到乐趣… According to Shodan, there are around 56,000 unprotected Redis instances in 2015. 根据 Shodan 的数据，2015 年大约有 5,6000 个不受保护的Redis实例。 According to ZoomEye, the distribution of the instances is. 根据 ZoomEye，实例的分布是。 According to ZoomEye, the top ranking countries of these instances are: China, USA, Germany… ZoomEye表示，这些例子中排名最高的国家是:中国、美国、德国…… Okay, back to the business. So how do we verify if a server is protected using python? It turns out to be fairly simple. 好了，回到正题。那么，我们如何验证是否使用 python 保护服务器呢？结果相当简单。 Use socket to connect to the target IP Perform a GET request If the server is unprotected, you GET request will succeed; otherwise it will fail 使用套接字连接到目标IP 执行GET请求 如果服务器不受保护，您的GET请求将成功;否则就会失败 Mitigation减轻 Don’t bind to 0.0.0.0 If you have to, change the default port (6379) Set a password (for everything) 不要绑定 0.0.0.0 如果有必要的话，修改默认端口 (6379) 为所有的 Reids 设置密码 Sep 11, 2018 （2018-09-11） author: Victor Zhu link: https://medium.com/@Victor.Z.Zhu/redis-unauthorized-access-vulnerability-simulation-victor-zhu-ac7a71b2e419]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整数反转]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2Freverse-integer%2F</url>
    <content type="text"><![CDATA[题目给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。 示例 1:12输入: 123输出: 321 示例 2:12输入: -123输出: -321 示例 3:12输入: 120输出: 21 注意: 假设我们的环境只能存储得下 32 位的有符号整数，则其数值范围为 [$−2^{31}$, $2^{31}$ − 1]。请根据这个假设，如果反转后整数溢出那么就返回 0。 题目链接 标签 数学 个人解答疑问点： 32 位的有符号整数需要怎么判断？ 思路：整数转成字符串类型，循环字符串字母进行处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 方法1 使用弱语特征转换function reverse($x) &#123; $rev = ''; $signed = ''; $x = (string)$x; for ($i = 0; $i &lt; strlen($x); $i++) &#123; if ($x&#123;$i&#125; == '-') &#123; $signed = '-'; continue; &#125; $rev = $x&#123;$i&#125; . $rev; &#125; $return = $signed . (int)$rev; if ($return &lt; pow(-2, 31) || (pow(2, 31)-1) &lt; $return) &#123; return 0; &#125; return $return;&#125;## 方法2 根据题解解题，方法比较奇特，断点了几次才理解实际思路function reverse($x) &#123;// $x = 123; $rev = 0; $max_val = pow(2, 31)-1; // 2147483647 $min_val = pow(-2, 31); // -2147483648 while ($x) &#123; $pop = $x % 10; // 取值最后一位 123 % 10 = 3, 12 % 10 = 2, 1 % 10 = 1; $x = bcdiv($x, 10); // 值进位 $x = 12, $x = 1 // 3 &gt; 214748364.7 || (3 == 214748364.7 &amp;&amp; 2 &gt; 7) if ($rev &gt; bcdiv($max_val, 10) || ($rev == bcdiv($max_val, 10) &amp;&amp; $pop &gt; 7)) return 0; // 3 &lt; -214748364.8 || (3 == -214748364.8 &amp;&amp; 2 &lt; -8) if ($rev &lt; bcdiv($min_val, 10) || ($rev == bcdiv($min_val, 10) &amp;&amp; $pop &lt; -8)) return 0; // 判断当前组装有没有越过范围，没有的话，判断当前是否和最大值除10后的值一样，再根据尾值判断是否越过范围 $rev = bcmul($rev, 10) + $pop; // 返回的值 0*10+3, 3*10+2, 32*10+1 &#125; return $rev;&#125; 做题总结一开始没有静下心来收集和拆分难点，所以一直拖到现在才做，做的时候意外的简单。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL 非对称加密]]></title>
    <url>%2F%E5%8A%9F%E8%83%BD%2FSSL%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[说明SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。而它的代表软件则是 OpenSSL。php 使用 openssl 函数则可以对 OpenSSL 进行调用。 原理非对称加密主要是通过 ssl 的公钥私钥都可以加密解密的特性来做的一个数据安全验证。使用到非对称加密技术的公司有支付宝、微博。大至交互流程如下： 前置准备 服务端需要开放公钥 接入方需要提供公钥给服务端 请求与返回 接入方请求服务端，使用自己的私钥生成加密串 服务端接收请求，根据请求里的用户编号取接入方公钥 根据接入方公钥对请求加密串进行校验 服务端处理完后，使用服务端私钥为返回数据添加加密串 接入方验证后进行指定处理 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?php$data = [ 'account_id' =&gt; 1,];$privateKeyId = openssl_pkey_get_private(file_get_contents('id_rsa'));openssl_sign(json_encode($data), $requestSign, $privateKeyId, OPENSSL_ALGO_SHA256);$data['sign'] = base64_encode($requestSign);// ===== 请求接口 ====$request = $data;$sign = base64_decode($data['sign']);unset($request['sign']);$userPublicKeyId = openssl_pkey_get_public(file_get_contents('id_rsa.pub'));if (! openssl_verify(json_encode($request), $sign, $userPublicKeyId, OPENSSL_ALGO_SHA256)) &#123; while ($error = openssl_error_string()) &#123; print_r($error); &#125;&#125;$response = [ 'status' =&gt; 200, 'message' =&gt; 'hello world'];$severPrivateKeyId = openssl_pkey_get_private(file_get_contents('private_key.pem'));openssl_sign(json_encode($response), $responseSign, $severPrivateKeyId, OPENSSL_ALGO_SHA256);$response['sign'] = base64_encode($responseSign);// ===== 接口响应 ====$ruslt = $response;$sign = base64_decode($ruslt['sign']);unset($ruslt['sign']);$severPublicKeyId = openssl_pkey_get_public(file_get_contents('public_key.pem'));if (! openssl_verify(json_encode($ruslt), $sign, $severPublicKeyId, OPENSSL_ALGO_SHA256)) &#123; while ($error = openssl_error_string()) &#123; print_r($error); &#125;&#125;// 处理业务逻辑 FQA为什么不是先使用服务端的公钥加密进行请求先呢？我一开始构思时是这样想的，请求使用服务端公钥加密，接口返回使用接入方的私钥进行解密。感觉并没有什么毛病，但是细细一想，这里涉及到证书安全问题和请求验证问题。 请求时使用的是服务端公钥，凭加密串上面的用户号是无法保证请求用户真实性 响应时如果接入方私钥泄漏，就可以被人直接模拟支付回调了]]></content>
      <categories>
        <category>功能</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何确认功能的开发时间]]></title>
    <url>%2F%E6%80%9D%E8%80%83%2F%E5%A6%82%E4%BD%95%E7%A1%AE%E8%AE%A4%E5%8A%9F%E8%83%BD%E7%9A%84%E5%BC%80%E5%8F%91%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[有很多人都对自己开发一个功能需要花费的时间什么不了解。报功能开发时间的时候总是靠感觉来。时间报长了还好解决，但是报的时间短了，自己就得加班才可以完成任务，抑或者完不成。 思考那些因素影响了开发时间通常影响因素是功能逻辑不了解或太复杂、功能需求频繁变更以及自身技术不熟练导致的。 1、功能需求频繁变更并不是自己的问题，可以要求增加开发时间，以防止自己每次都为变更买单。2、逻辑不了解或太复杂需要花时间去理清，不要急着去开发，要不然很容易出现做着做着就去问细节的情况或做完被说和想要的完全不一样。3、最后技术的问题就是自己的锅了，加班也无话可说（就当为自己学习买单，还是很有好处的）。 问功能需要花多少时间时，应该怎么回答推荐不要马上随感觉来定时间，可以说：“在中午休息前给你答复可以吗？” 这样可以预留更多的时间给需求进行评估。如果别拒绝了，可以问下别人的底线：“这个功能最迟什么时候要？”。注意喔，这样问他很可以是很前端和测试的时间都算上去的，并不是单单后台开发的时间。如果连这个要求都拒绝了，那真的需要考虑换公司了。因为连功能什么时候需要完成都不清楚。 估错了任务时间该怎么办很多时候就算很认真的去预估开发时间，也会有估时过长，估时过短的问题。估时过长的还好，可以问上级要新需要来开发，或是学习都随你。估时过短并不是自己闷头加班去解决，这是最后的做法。应该提前向上级汇报，说明错估原因，尽可能的拿到更多的开发时间。如果你不向上级汇报导致项目被延期，所有后果将由自己承担。 结论我们需要更加的了解自己的能力，那些地方花的时间过多了，那些地方可以做的更好。这些都是可能通过一次次统计去了解的。]]></content>
      <categories>
        <category>思考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Explain SSL Pinning with simple codes(用简单代码解释 SSL 固定)]]></title>
    <url>%2F%E7%BF%BB%E8%AF%91%2Fexplain-ssl-pinning-with-simple-codes%2F</url>
    <content type="text"><![CDATA[HTTPS and SSL PinningHTTPS 和 SSL 固定There are two major factors in an HTTPS connection, a valid certificate that server presents during handshaking, and a cipher suite to be used for data encryption during transmission. The certificate is the essential component and serves as a proof of identity of the server. The client will only trust the server if the server can provide a valid certificate that is signed by one of the trusted Certificate Authorities that come pre-installed in the client, otherwise, the connection will be aborted. HTTPS 连接有两个主要因素，握手时服务器提供一个有效证书，以及在传输过程中用于数据加密的密码套件。证书是基本组件，用作服务器身份的证明。只有当服务器能够提供由预装在客户机中的受信任证书颁发机构之一签名的有效证书时，客户机才会信任服务器，否则连接将被中止。 An attacker can abuse this mechanism by either install a malicious root CA certificate to user devices so the client will trust all certificates that are signed by the attacker, or even worse, compromised a CA completely. Therefore relying on the certificates received from servers alone cannot guarantee the authenticity of the server, and it is vulnerable to potential man-in-the-middle attack. 攻击者可以滥用此机制，方法是向用户设备安装恶意根CA证书，以便客户机信任由攻击者签名的所有证书，或者更糟，完全破坏CA。因此，仅依靠从服务器接收到的证书无法保证服务器的真实性，容易受到潜在的中间人攻击。 SSL Pinning is a technique that we use in client side to avoid man-in-the-middle attack by validating the server certificates again even after SSL handshaking. The developers embed (or pin) a list of trustful certificates to the client application during development, and use them to compare against with the server certificates during runtime. If there is a mismatch between the server and the local copy of certificates, the connection will simply be disrupted, and no further user data will be even sent to that server. This enforcement ensures that the user devices are communicating only to the dedicated trustful servers. SSL 固定是我们在客户端使用的一种技术，通过在 SSL 握手之后再次验证服务器证书来避免中间人攻击。开发人员在开发期间向客户机应用程序嵌入(或pin)一组可信证书，并在运行时使用它们与服务器证书进行比较。如果服务器和证书的本地副本不匹配，则连接将被中断，甚至不再向该服务器发送用户数据。这种强制确保用户设备只与专用的可信服务器通信。 However, developers must take extra caution in SSL Pinning, When a pinned certificate is expired and the server has updated a new certificate, since the new certificate is definitely different from the pinned one that the client currently has, the clients will not trust the updated certificate and therefore terminate the connection, in which no further communications can be established between clients and servers, so the application is basically ‘bricked’. Therefore, to avoid such situation, it is always advisable to pin the future certificates in the client applications before release. 然而,开发人员必须采取额外的谨慎在SSL固定,当固定证书过期和服务器已经更新一个新的证书,自从新证书肯定是不同的固定客户目前,客户不会信任更新后的证书,因此终止连接,没有进一步的客户端和服务器之间的通信可以建立,所以应用程序基本上是“给”。因此，为了避免这种情况，通常建议在发布之前将未来的证书固定在客户机应用程序中。 There are usually two ways we can achieve SSL Pinning in client applications. Pin either the whole certificate or its hashed public key. The hashed public key pinning is the preferred approach because the same private key can be used in signing the updated certificate, therefore we can save the trouble of pinning a new hashed public key for a new certificate, and reduce the risk of app ‘bricking’. 通常有两种方法可以在客户机应用程序中实现SSL固定。对整个证书或其散列公钥进行Pin。散列公钥固定是首选方法，因为可以使用相同的私钥对更新后的证书进行签名，因此我们可以省去为新证书固定新散列公钥的麻烦，并降低应用程序“变黑”的风险。 Codes In Action代码在行动I am going to write a simple Android application that communicates with &lt;www.google.com&gt;, and use Charles proxy as a man-in-the-middle server, and finally demonstrate how an effective SSL Pining can stop man-in-the-middle attack. 我将编写一个与 &lt;www.google.com&gt; 通信的简单 Android 应用程序，并使用Charles proxy作为中间人服务器，最后演示一个有效的 SSL Pining 如何阻止中间人攻击。 Please note that the following codes are for educational purpose and they are not meant for use in production. Please consider using a mature solution from reputable libraries such as okhttp for your application. 请注意以下代码是用于教育目的，并不用于生产。请考虑为您的应用程序使用来自声誉良好的库的成熟解决方案，比如 okhttp。 123456789101112131415161718192021222324252627// Read the pinned certificate from local (i.e., assets folder)// 读取本地固定证书val inputStream = context.assets.open("google.crt")val pinnedCertificate = CertificateFactory.getInstance("X.509") .generateCertificate(inputStream)// Create a request to www.google.com// 创建一个 www.google.com 的请求val url = URL("https://www.google.com")val httpsUrlConnection = url.openConnection() as HttpsURLConnection// Establish the connection// 建立连接httpsUrlConnection.connect()// Check the certificates and see if one of the server certificates// matches the pinned certificate// 检查证书，看看其中一个服务器证书是否与固定证书匹配if (httpsUrlConnection.serverCertificates.contains(pinnedCertificate)) &#123; // Open stream // 打开流 httpsUrlConnection.inputStream Log.d("Pinning", "Server certificates validation successful")&#125; else &#123; Log.d("Pinning", "Server certificates validation failed") throw SSLException("Server certificates validation failed for google.com")&#125; The above codes are self-explanatory. The server certificates from HttpsUrlConnection are to be checked against with the local pinned certificate, the connection input stream will be open if there is a certificate match, and an SSLException will be thrown otherwise. 以上代码是不言自明的。将使用本地固定证书检查来自 “HttpsUrlConnection” 的服务器证书，如果证书匹配，连接输入流将打开，否则将抛出 “SSLException”。 I use openssl command to download the &lt;www.google.com&gt; certificate and save it as a pinned certificate in the assets folder. Just run this code and you will see message Server certificates validation successful in the logcat. 我使用openssl命令下载证书，并将其保存为固定在assets文件夹中的证书。只要运行这段代码，您将在logcat中看到消息“服务器证书验证成功”。 Now fire up Charles, and install Charles root certificate to the test device and configure test device proxy setting to the IP address of Charles service. With Charles root certificate being installed as trusted CA, Charles now acts as a man-in-the-middle, and all the certificate signed by Charles will be trusted by the client system by default. However, since we have pinned the legit &lt;www.google.com&gt; certificate in our demo application, the server certificate validation will fail in this case. 现在启动 Charles，将 Charles 根证书安装到测试设备，并将测试设备代理设置配置为 Charles 服务的 IP 地址。将 Charles 根证书安装为 trusted CA 后，Charles 现在充当中间人的角色，在缺省情况下，客户机系统将信任 Charles 签名的所有证书。但是，由于我们在演示应用程序中固定了 legit 证书，因此在这种情况下服务器证书验证将失败。 Run the test application with Charles proxy enabled, as expected, you will see SSLException with message Server certificates validation failed for google.com in the logcat. 运行启用了 Charles proxy 的测试应用程序，如预期的那样，您将在 logcat 中看到 “SSLException” 和消息 “Server certificates validation failed for google.com”。 Further reading扩展阅读The purpose of this post is just to provide an entry-level introduction to SSL Pinning technique, you can read the original proposal from Paypal engineering team, and learn more about the bug that results in ineffective SSL Pinning in Java/Android. 本文的目的只是提供SSL固定技术的入门介绍，您可以阅读 Paypal 工程团队的original proposal 了解更多关于导致 Java/Android 中SSL固定无效的 bug。 Oct 23, 2018 （2018-10-23） author: Zhang QiChuan link: https://medium.com/@zhangqichuan/explain-ssl-pinning-with-simple-codes-eaee95b70507]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>ssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两数之和]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2Ftwo-sum%2F</url>
    <content type="text"><![CDATA[题目给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 示例: 给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9所以返回 [0, 1] 题目链接 标签 数组 哈希表 个人解答12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 方法1function twoSum($nums, $target) &#123; $count = count($nums); for ($i=0; $i &lt; $count; $i++) &#123; for ($j=($i+1); $j &lt; $count; $j++) &#123; // $j 之是 $i+1 是因为不能重复利用数组中同样的元素。 if (($nums[$i]+$nums[$j]) == $target) &#123; return [$i, $j]; &#125; &#125; &#125; return [];&#125;# 方法2：建立值键对应function twoSum($nums, $target) &#123; $count = count($nums); $values = []; for ($i=0; $i &lt; $count; $i++) &#123; $values[$nums[$i]] = $i; &#125; for ($i=0; $i &lt; $count; $i++) &#123; $value = $target - $nums[$i]; if (isset($values[$value])) &#123; return [$i, $values[$value]]; &#125; &#125; return [];&#125;# 方法3: 通过值找键function twoSum($nums, $target) &#123; for ($i=0; $i &lt; count($nums); $i++) &#123; $searchValue = $target - $nums[$i]; // array_search 是语言自带的函数，应该和方法2差不多。 if ($key = array_search($searchValue, $nums)) &#123; return [$i, $key]; &#125; unset($nums[$i]); &#125; return [];&#125;# 方法4：匹配不到的值存放到数组中，方便后面查找function twoSum($nums, $target) &#123; $values = []; for ($i=0; $i &lt; count($nums); $i++) &#123; $value = $target - $nums[$i]; if (isset($values[$value])) &#123; return [$i, $values[$value]]; &#125; $values[$nums[$i]] = $i; &#125; return [];&#125; 做题总结虽然两数相加得到结果很简单，但是没有实现思路逃避了许久。后面看了解答的文字，不看代码。才以最简单的方式做出来。 未掌握知道点 空间/时间复杂度计算 双循环掌握不好]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览量统计]]></title>
    <url>%2F%E5%8A%9F%E8%83%BD%2Freview%2F</url>
    <content type="text"><![CDATA[需求统计商品和品牌的浏览量。品牌和商品的关系是一对多。 实现方式直接改库最差的解决方案，会影响整个数据表的性能。 使用 redis 进行记录方法1： 每访问一次，添加一个消息队列（只需存在访问对向的 ID 即可）。通过定时任务每 5 分钟处理一次队列，处理完会删除队列。通过队列内容取指定的关联映射到 redis hash 中。为了保证数据不丢失，还有一个定时任务对数据库统计字段进行更新。队列格式和 hash 格式如下： 123456&apos;goods&apos; =&gt; [ &apos;1&apos; =&gt; 1, // 商品ID =&gt; 访问数量]&apos;brand&apos; =&gt; [ &apos;1&apos; =&gt;1, // 品牌ID =&gt; 访问数量] 方法2： 每次访问都进行直接追加。而读取时直接读取 reids 里的值，这样实时性比较高。还需要一个定时对统计数量进行更新（每天只需执行一次）。]]></content>
      <categories>
        <category>功能</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 提交日志回顾总结]]></title>
    <url>%2F%E5%B7%A5%E5%85%B7%2Fgit-think%2F</url>
    <content type="text"><![CDATA[说明年前我需要编写公司当年的工作总结，所以把项目里的提交日志拉出来查看，其中有几类提交是无效的也是没有意义的，整理起来十分蛋疼，所以记录下来。 示例只有操作类型 fix add 上面这两个可以知道是修复功能和添加功能，但是需要看代码才能知道修复的是什么，添加的是什么。 提交说明使用外文进行说明 fix refund 英文不好的人可能看到英文得需要想几秒，甚至需要翻译。 无详细说明 严重BUG修复 退货退款时间记录 虽然知道是修复严重 BUG，但是 BUG 是什么功能，为什么是严重 BUG 并不知道。而第二种虽然没多大毛病，但改成 “补充遗漏退货退款完成时间” 会更好些。 多个功能混在一起提交 修改xxx 添加xxx 去除xxx 不建议这样子提交，但是后面回顾代码的时候区分不出每个项对应的内容。不要怕提交条数多，如果需要审阅代码就知道分开提交的好处了。 无意义的说明 修复 xxx 文件 提交记录里会记录当次提交的所有文件，没有说明的意义。 使用 GitHub issues 的方式提交 fix issues #894 这种提交是模仿 GitHub 上的提交方式，它会自动关联上指定的 issues，对直接在 GitHub 上审阅代码时很好用。但是对于完全独立的代码仓库来说，会不知道具体的问题是什么。可以保留这个方式写在说明第二行即可。gogs 也有类似的功能。但对于禅道，这种没有关联的来说，完全没有必要记录上去。 总结 对提交进行分类 统一提交格式 过段时间回来查看提交记录还能看明白提交说明，那就代表说明表述上没有问题 1234567891011121314feat: xxx 功能详细说明：fix: xxx 功能的 xxx 问题详细说明：关联issues：#123del: xxx 功能[的弃用 xxx 方法]详细说明：adjust: xxx 功能[的 xxx]详细说明：[] 可选的内容]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志深入理解]]></title>
    <url>%2F%E6%A6%82%E5%BF%B5%2Flog%2F</url>
    <content type="text"><![CDATA[说明很多软件，系统都会有着自己的日志，记录日志的主要目的是什么呢。 日志可以记录谁谁谁在什么时候做了什么事情，这些记录可以让我们知道用户是怎么操作系统报的错误。可用来找错也可以通过一些日志分析软件去分析，最近用户做那些操作比较多。搜索什么关键词比较多，有利于运营的策略制定。可用来分析 例子 windows 事件查看器里的 windows日志是一个很好的例子。它分为应用程序日志，安全日志，系统日志 应用程序日志：主要记录系统软件应用的错误安全日志：比较敏感的系统操作，如管理员登录，修改密码系统日志：系统相关的操作，如windows的服务操作 所有的日志都记录了错误级别，日期时间，来源，任务类型，系统用户，计算机，日志内容 通过日志记录的内容，可以轻易的得知软件的错误是什么。 它还提供了筛选和排序的功能，方便我们去查找错误。 基础概念主要记录的日志内容 错误级别 日期时间 来源 IP 项目名 任务类型 日志内容 操作内容的简写 用户的请求参数，可用 json 项目的日志没有windows日志里的那么细，因为我们面对的范围比它小太多了，有些内容就没有必要记录 记录格式 json：这个可以很好的区分数据是那一项里面的，但是在直接查看上不是很直观，需要取出转格式，有些内容还会有换行的。 字符串：直接查看日志文件比较直观，但是如果需要导入分析工具时，需要写正则一项项匹配出来，再导入 日志存储方式 数据库 个人十分不推荐的记录方式，因为日志只要有人访问程序就会写库。访问少倒无所谓，访问大会大量消耗数据库的性能 写数据库慢，高并发的时候会锁表 文件 这个比数据库好很多，也比较传统的做法。会占用系统IO，写操作太多时会导致系统卡顿。不考虑被攻击时可直接使用 统计和查找没有数据库那么功能丰富，可以直接导至分析系统中进行操作。 扩展：知道自己服务器的 IO 写入速率，去估算每分钟可以写多少日志， 假如服务器写入速率是 100k/s 其他软件预计占用 30k/s 去除容差 20k/s 那可用的是 50k/s 每分钟可写 51200b 的日志 再设每条日志 500b 那每分钟级最多可写102条日志 内存 读写速度很快，但是内存一般不会很大，普遍4g以上。去除其他应用的内存开销，可用的内存并不多。可以定时转存到日志文件中 除了数据库不推荐外，使用文件还是使用内存的可能通过写入条数进行估算。使用什么方式 程序实现规范 php 的 psr-3 难点： 1. 要记日志的地方那么多，怎么对其进行简化操作 通过URL匹配来记录大概操作 通过php异常处理记录错误日志，与 [上一期文章](https://segmentfault.com/a/1190000016824772) 关联 特殊的需求做直接记录处理，如：搜索关键词词频统计最近热门关键词 管理 elk: elsticsearch + logstash + kibana 比较流行的一套日志分析系统 自制管理系统 写在最后日志不管是对系统还是对个人来说都是很有必要存在的东西。 身边的事物总会在某个时间点消逝，我们需要珍惜，留有美好的记忆，去记录它，直到某天返回翻看，回忆起当时留有的酸甜苦辣。]]></content>
      <categories>
        <category>概念</category>
      </categories>
      <tags>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php异常处理的深入]]></title>
    <url>%2F%E6%B7%B1%E5%85%A5%2Fphp-exception%2F</url>
    <content type="text"><![CDATA[引出如果你调一个类，调用时数据验证时报了个错，你会以什么方式返回 数组，布尔值？ 数组这个可以带错误原因回来，那布尔值呢？ 返回了个 false, 报错时把错误放在类变量里？还是专门用一个获取错误的方法进行获取？ 上面说的情况是代码完全没有问题的情况。那如果是一些第三方的工具包，你又怎么知道他里面的执行会不会导致整个系统崩溃。 你说本地运行是没问题的，环境这种东西不好说。 所以我们就用到了 异常 这个东西 下面是我们需要了解的问题 什么时候抛异常？怎么接异常？异常要怎么处理？他的使用场景又是什么？ 基础知识 基础操作 try … catch() throw 错误级别 致命错误 E_ERROR， 语法错误 E_PARSE， 警告错误 E_WARNING， 通知错误 E_NOTICE php异常处理类 预定义异常 1* ErrorException (extends Exception) SPL异常类 1234567891011121314* LogicException (extends Exception) // 表示程序逻辑中的错误的异常。这种异常应该直接在代码中的修复 * BadFunctionCallException // 回调调用未定义的函数或缺少一些参数时会抛出该异常 * BadMethodCallException // 回调方法是一个未定义的方法或缺失一些参数时会抛出该异常 * DomainException // 值不遵守定义的有效数据域时会抛出该异常 * InvalidArgumentException // 参数不是预期类型时会抛出该异常 * LengthException // 长度无效时会抛出该异常 * OutOfRangeException // 请求非法索引时引发的异常，这应该在编译时就检测到的错误* RuntimeException (extends Exception) // 在运行时发生的错误会抛出该异常 * OutOfBoundsException // 值不是有效键时会抛出该异常，这表示在编译时无法检测到的错误 * OverflowException // 在向完整容器中添加元素时引发的异常 * RangeException // 在程序执行期间为指示范围错误而引发的异常。通常这意味着除了/overflow以外还有一个算术错误。这是运行时的DomainException版本 * UnderflowException // 在空容器上执行无效操作(如删除元素)时引发的异常 * UnexpectedValueException // 值与一组值不匹配时会抛出该异常。通常，当一个函数调用另一个函数并期望返回值为某种类型或值(不包括算术或缓冲区相关错误)时，就会发生这种情况 异常处理相关函数 12345error_reporting // 设置报告的错误级别register_shutdown_function // 注册一个会在php中止时执行的函数set_error_handler // 设置用户自定义的错误处理函数set_exception_handler // 设置用户自定义的异常处理函数error_get_last // 获取最后发生的错误 使用场景 系统 主要抓的是无法预测的错误，统一返回，没有使用 try…catch 接收的异常直接跳进设置的方法中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?phpnamespace App\Exception;use Exception;/** * 异常句柄（入口）类 */class Handler&#123; // 默认错误处理 public static function errorHandler($errno, $errstr, $errfile = '', $errline = 0) &#123; &#125; // 默认异常处理 public static function exceptionHandler($ex) &#123; try &#123; throw $ex; &#125; catch (Order $e) &#123; echo "订单异常"; &#125; catch (Goods $e) &#123; echo "商品异常"; &#125; catch (User $e) &#123; echo "用户异常"; &#125; catch (Exception $e) &#123; echo "其他异常"; &#125; &#125; // 致命错误处理 public static function fatalErrorHandler() &#123; if ($e = error_get_last()) &#123; print_r($e); &#125; &#125;&#125;/** * 订单异常 */class Order extends Exception&#123;&#125;/** * 商品异常 */class Goods extends Exception&#123;&#125;/** * 用户异常 */class User extends Exception&#123;&#125; 12345678910&lt;?php// 入口文件中error_reporting(E_ERROR | E_WARNING | E_PARSE | E_NOTICE);register_shutdown_function(array('App\\Exception\\Handler', 'fatalErrorHandler'));set_error_handler(array('App\\Exception\\Handler', 'errorHandler'));set_exception_handler(array('App\\Exception\\Handler', 'exceptionHandler')); 工具 定义自定义的异常，一有错误直接抛出。使用工具的程序只需通过 Exception 接收异常即可, 所有异常都通过这个进行处理的 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?phpnamespace Testlin\Db\Exception;use Exception;interface ExceptionInterface&#123;&#125;class Db extends Exception implements ExceptionInterface&#123;&#125;class Pdo extends Db&#123;&#125;?&gt;&lt;?phpnamespace Testlin\Db;use Exception;use Testlin\Db\Exception\Pdo;class Db&#123; protected $db; public function __construct($config) &#123; $this-&gt;db = new PDO($config); if ($this-&gt;db == false) &#123; throw new Pdo("连接失败"); &#125; &#125;&#125;?&gt; 文章例子 工具包例子 项目例子 FQA1、为什么要定自定义异常类, 系统不是已经给了很多选择，而且很多 composer 包里都只是继承一下。 答：其实自定义异常是为了用区分异常颗粒度的，比如 我定了 订单异常，商品异常，用户异常 类，但是 订单里的异常多种多样，比如订单支付异常，订单生成异常。 * RuntimeException (extends Exception) * Order * Paymen * Created * Goods * User * Withdraw 当项目抛出异常时 123456789&lt;?php try &#123; $param = []; // 操作那个方法时传的参数 throw App\Exception\Order\Payment::forParam('执行xxx操作异常', $param); &#125; catch (Exception $e) &#123; // 相关操作 get_class($e); // 当前异常类 App\Exception\Order\Payment &#125; 通过异常类名，我们可以知道是订单支付异常。这里可以代替错误号，而且更清晰明了 2、为什么有一些 composer 包里的自定义异常，有的有很多方法。有什么用处吗？ 作用1：格式化异常 比如：抛出的异常提示是 “id=xx 的用户不存在”，我们会有以下两种写法 12345678910111213141516171819202122&lt;?php// 普通操作$id = 1;throw new Payment("id=&#123;$id&#125; 的用户不存在");// 格式化异常use App\Exception\Order;class Payment extends Order&#123; public static function forId($id) &#123; return new self(sprintf( 'id=%s 的用户不存在', $id )); &#125;&#125;$id = 1;throw Payment::forId($id); 作用2：组件级别的异常 12345678910111213141516171819202122232425&lt;?phpnamespace Testlin\Db\Exception;use Exception;interface ExceptionInterface&#123;&#125;class Mysqli extends Exception impements ExceptionInterface&#123;&#125;class Pdo extends Exception impements ExceptionInterface&#123;&#125;try &#123; throw new Testlin\Db\Exception\Mysqli('sql 执行失败');&#125; catch (Testlin\Db\Exception\ExceptionInterface $e) &#123; // 这里取得的异常只会是继承这个接口的异常 // 可以只针对这个工具包进行处理&#125;]]></content>
      <categories>
        <category>深入</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[satis composer 本地仓库搭建]]></title>
    <url>%2F%E5%B7%A5%E5%85%B7%2Fcomposer-local-repository%2F</url>
    <content type="text"><![CDATA[环境 windows nginx php composer 安装拉取 satis 项目包，并拉取项目依赖 12345composer create-project composer/satis --stability=devcd satiscomposer install 配置修改 satis/config.json 文件，文件内容如下 123456789101112131415161718192021&#123; "name": "composer 本地仓库", "homepage": "http://packages.example.org", // 访问域名 "repositories": [// 要拉取包的仓库地址 &#123; "type": "vcs", "url": "https://github.com/test-lin/db.git" &#125;, &#123; "type": "vcs", "url": "https://github.com/test-lin/queue.git" &#125;, &#123; "type": "vcs", "url": "https://github.com/test-lin/cache.git" &#125;, &#123; "type": "vcs", "url": "http://192.168.6.251:3000/php/xjwSpider.git" &#125; ], "require": &#123; // 要拉取到本地的包文件 注：不会包含包的依赖 "test-lin/db": "*", "test-lin/queue": "*", "test-lin/cache": "*", "php/xjwSpider": "*" &#125;, "archive": &#123; "directory": "dist", "format": "tar", "prefix-url": "http://packages.example.org" // * 这个参数是当前项目的域名，作用是以zip压缩包的方式直接下载包文件 &#125;&#125; 拉取包到本地仓库web/ 是本地仓库访问地址。 1php bin/satis build config.json web/ 如果需要定时更新，则需要配置定时任务去定时更新 设置本地仓库nginx 设置虚拟主机 12345678910111213server &#123; listen 80; server_name packages.example.org; root /var/www/satis/web; index index.php index.html; location ~* \.php$ &#123; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; &#125;&#125; 使用本地仓库中的包composer.json 文件中添加以下 json 拉取，即可获取本地库了. 如果本地仓库不存在且有网络会去网络中获取。repositories 参数可以设置多个 123456&#123; "repositories": [&#123; "type": "composer", "url": "http://packages.example.org" &#125;]&#125; FQA1. github 的包需要配置 token123Could not fetch https://api.github.com/repos/test-lin/db/git/refs/heads?per_page=100, please create a GitHub OAuth token to go over the API rate limitHead to https://github.com/settings/tokens/new?scopes=repo&amp;description=Composer+on+packages.example.org+2018-06-28+0310to retrieve a token. It will be stored in "/home/vagrant/.config/composer/auth.json" for future use by Composer. 解决方法： 访问命令行中提示的 https://github.com/settings/tokens/new?scopes=repo&amp;description=Composer+on+packages.example.org+2018-06-28+0310 复制 token description 文本框中内容 拉到页底 点击 generate token 在命令行中粘贴复制内容确认限可 2. 私有包，拉取不了解决方法： 本地生成 ssh key ，配置到要拉取项目的平台即可，免密拉取了 123ssh-keygen -t rsacat ~/.ssh/id_rsa.pub 以 gogs 为例 3. composer 不支持 http1Your configuration does not allow connections to http://192.168.6.251:3000/php/xjwSpider.git. See https://getcomposer.org/doc/06-config.md#secure-http for details. 解决方法： 1composer config -g secure-http false 4. 拉取的包 composer.json 配置有误12[Composer\Repository\InvalidRepositoryException]No valid composer.json was found in any branch or tag of http://192.168.6.251:3000/php/xjwSpider.git, could not load a package from it. 解决方法： 确保项目根部有 composer.json composer.json 里需要设置 name]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>composer</tag>
        <tag>satis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.1 Xdebug的安装配置]]></title>
    <url>%2F%E5%B7%A5%E5%85%B7%2Fxdebug-install-and-config%2F</url>
    <content type="text"><![CDATA[介绍我之前配置直接按网上的文章进行配置总是配置不成功，里面很多东西不了解。当我在 xdebug 官网看到了 xdebug 远程调试原理图时，我才知道应该怎么配置 xdebug。配置的参数也少了很多，也不需要在 IDE 里对一个个请求地址进行配置。体验比之前看到的文章设置好用多了 环境说明 windows vagrant+vbox+centos7+nginx+php phpstorm 配置前准备 检查 php 环境是否已经存在 xdebug 拓展了 在命令行中输入 php -m 可以查看 php 已加载的拓展 了解自己环境的配置 php 版本 php.ini 所在地址 服务器系统位数 32位 还是 64位 xdebug 和 phpstorm 交互的原理 服务器的IP和端口是 10.0.1.2:80 IDE 的客户端IP是 10.0.1.42, 所以服务器上 xdebug.remote_host=10.0.1.42 IDE 监听的调试端口为 9000, 所以服务器上 xdebug.remote_port=9000 IDE 所在的客户端，对 xdebug 的服务器进行请求 Xdebug 与 10.0.1.42:9000 的客户端 IDE 监听端口关联 运行调试, xdebug 所在的服务器提供 HTTP 响应 服务器的IP和端口是 10.0.1.2:80 IDE 的客户端IP是一个未知的IP, 所以服务器上 xdebug.remote_connect_back=1 IDE 监听的调试端口为 9000, 所以服务器上 xdebug.remote_port=9000 发出 HTTP 请求后，Xdebug 将从 HTTP 请求头获取 IP 地址 Xdebug 会和从 HTTP 请求头获取 IP 地址的客户端 IDE 监听端口关联 运行调试, xdebug 所在的服务器提供 HTTP 响应 下载缺少的扩展和软件 phpstorm 编辑器 xdebug 扩展 配置php 环境配置添加 xdebug 扩展 下载 xdebug 扩展源码 123456cd /usr/local/srcwget https://xdebug.org/files/xdebug-2.7.0alpha1.tgz解压tar -zxvf xdebug-2.7.0alpha1.tgz 编译安装 123456789101112131415161718cd xdebug-2.7.0alpha1生成安装脚本phpize设置安装配置参数vim install-sh&gt; /configure --with-php-config=/usr/local/php/bin/php-config运行安装配置sh install-sh编译扩展，使用两个 cpu 内核运行（可以快很多）make -j 2编译安装make install 注意： 编译安装后，会返回扩展所在文件夹。 php.ini 中添加 xdebug 配置 12345678[xdebug]zend_extension=&quot;/usr/local/php/lib/php/extensions/no-debug-non-zts-20160303/xdebug.so&quot;xdebug.idekey=&quot;PHPSTORM&quot;xdebug.remote_enable = Onxdebug.remote_autostart=Onxdebug.remote_connect_back=Onxdebug.remote_port=9001 phpstorm 配置 打开设置 file -&gt; settings -&gt; Languages &amp; Frameworks 设置项目使用环境 设置 debug 配置 Languages &amp; Frameworks -&gt; php -&gt; debug 设置 xdebug dbgp 配置 Languages &amp; Frameworks -&gt; php -&gt; debug -&gt; dbgp proxy 设置当前项目所在服务器地址和域名 开始调试 打开编辑器调试监听 在指定控制器中添加断点 请求地址，编辑器会自动进入调试模式中 系列文章 xdebug的安装配置 [本篇] xdebug的实际运用 xdebug性能分析 FQA我的 php 运行环境在 windows 下应该要怎么设置windows 的添加扩展会比 linux 简单很多。直接下载 dll 扩展文件就可以了。除了 zend_extension 设置的地址不一样。其他可以 xdebug 配置可以共用。 php.ini 中配置 xdebug 为什么不用默认的 9000 端口因为 php-fpm 是使用 cgi协议 进行运行，所以它也需要端口，而它默认的端口也是 9000。如果你像我这样使用虚拟机的方式进行访问项目，不会出问题。但是如果你使用的是本地的 php-fpm 那他就会出现端口被占用的情况。为了避免就直接用 9001 来代替默认端口 php.ini 中可以配置的 xdebug 参数有那些，我应该在那里得到更全面的参数说明xdebug 官网那里的手册有详细说明， xdebug 远程连接文档链接 里的 ctrl + f 搜索 Related Settings 就可以看到连接参数了 我应该下载那个版本的 xdebug如果实在不知道自己的 windos 系统的 php 环境该用那个版本的扩展可以通过下载页提供的工具进行下载 工具链接 多行文本框里面是放通过 php -i 命令返回的配置内容为了更完整的取得参数可以 php -i &gt; D:/php-ini.txt 保存到文件中 为什么我的 ide 配置好后，启动调试监听没有效果这个很有可能是你系统的防火墙的安全机制。把这个端口保存起来了，可以直接关闭防火墙进行调试]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>xdebug</tag>
        <tag>phpstorm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.2 xdebug的实际运用]]></title>
    <url>%2F%E5%B7%A5%E5%85%B7%2Fxdebug-use%2F</url>
    <content type="text"><![CDATA[介绍在 上一期 中我们已经把 xdebug 和 phpstorm 的关联配置设置好了，接下来我将会深入的介绍 debug 的运用。分为3点内容 快速找到错误的原因 辅助读懂比效复杂的代码 代码重构 环境说明 windows vagrant+vbox+centos7+nginx+php phpstorm 学前准备 xdebug + phpstorm 调试环境已经可以正常运行 调试跳转 图标 描述 当当前应用程序停止时，单击此按钮再次调试。 单击此按钮可暂停程序执行。 单击此按钮，通过标准关闭脚本从外部终止当前进程。 单击此按钮以打开断点对话框，您可以在其中配置断点行为。 使用此按钮切换断点状态。 单击此按钮以突出显示编辑器中的当前执行点，并在框架窗格中显示相应的堆栈框架。 单击此按钮执行程序，直到当前方法或文件中的下一行，跳过在当前执行点引用的方法(如果有的话)。如果当前行是方法中的最后一行，则执行步骤到在此方法之后执行的行。 f7单击此按钮，使调试器步骤进入在当前执行点调用的方法。 单击此按钮，调试器将从当前方法中退出，并立即执行该行。 单击此按钮恢复程序执行并暂停，直到执行点到达编辑器中当前游标位置的行。不需要断点。实际上，插入符号处的当前行有一个临时断点集，一旦程序执行暂停，就会删除它。因此，如果插入符号位于已经执行的行上，则程序将重新开始执行，因为无法回滚到以前的断点。当您深入到方法序列中并需要st时，这个操作特别有用 快速找到错误的原因在开发中我们经常会碰到很多 bug。一般有以下几种 php 语言报错 报错时，我们应该先看下报错内容，这很重要，他可以让你知道你的代码错那里了。一般会返回给你错误是那一行，环境装了 xdebug 后还会显示错误的地址运行时经过了那些文件，那些方法 写数据库操作失灵 这个错误难度就高了些。因为你需要了解当前业务需要改那些数据表。操作过后那张表的数据漏了。这个操作你有没有写。虽然说只要自己了解业务就可以不用调试也可以快速解决，但是传参或返回很复杂。那这个就很适合了 辅助读懂比效复杂的代码工作中并不是全都是自己使用框架开发，有时还会为了进度使用一些开源的项目（ecshop，dedecms）。也可能是前同事遗留的代码。自己写的东西很容易看懂，但是看别人的东西，如果写的不好那绝对是恶梦。你会在看都不想看，心里在吐槽代码不合理的地方。心中始终十分抗拒，导致功能变更延期。 复杂的代码只需要知道它会接收什么参数，返回什么东西就可以了。如果不是很重要完全可以不看它内部的内容。把它隔离开来。 学习技术超前的代码运行逻辑。那就需要进行断点调试了。 代码重构代码重构是维护一个写的很烂的项目必需经历的过程。重构的核心也是知道指定的方法有那些改变，或把它拆分出来。或把它整合到一块。 断点查看原逻辑有那些操作，记录下来，如果不是算法，主要记录的还是数据表操作 每个操作都有传参和返回，在调试模式下我们很容易就知道访问方法前环境中有那些参数可供使用 重构完后，可以使用相同的请求参数来访问重构代码。结果一致就为重构完成了 系列文章 xdebug的安装配置 xdebug的实际运用 [本篇] xdebug性能分析 FQA 文章字太多了，不想看 我的文章有对应的视频，你可以通过视频来进行学习这一期的内容。但是你不要吐槽我语言表达能力和普通话，因为我平时也不怎么说话，想练习口才才做的视频。附上 链接]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>xdebug</tag>
        <tag>phpstorm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.3 xdebug性能分析]]></title>
    <url>%2F%E5%B7%A5%E5%85%B7%2Fxdebug-property%2F</url>
    <content type="text"><![CDATA[介绍在上两期中我已经对 xdebug 最核心的操作已经进行了讲解。相信你可以摆脱写 var_dump($data);die; 的编写和完成调试后的清除了。这一期我们来学习xdebug的第二个特色-性能分析。这一个功能，在实操中用的不是很多。 使用场景： 高并发项目的核心功能优化。通过查看运行一个方法经过的依赖耗时情况，进行代码优化。 环境说明 windows vagrant+vbox+centos7+nginx+php phpstorm 学前准备 xdebug + phpstorm 调试环境已经可以正常运行 学习点 明白 xdebug 性能分析需要做那些配置 知道怎么去看性能报告 xdebug 配置xdebug 是通过访问指定方法。生成性能分析文件，再通过分析软件进行查看性能结果。 php.ini 添加配置 123456xdebug.profiler_enable=Offxdebug.profiler_enable_trigger=Onxdebug.profiler_enable_trigger_value="create"xdebug.profiler_output_dir="/tmp/"xdebug.profiler_output_name="cachegrind.out.%R" phpstorm 分析性能文件比较建议一个方法访问完后，生成分析文件，马上进行性能分析，分析完后再清除文件。为了数据准确性，我们还需要进行多次对比。找性能参数的平均值来提高准确性。 我们得知道那个依赖方法耗时最久，是什么原因。有没有优化的可能。 phpstorm xdebug 性能分析工具详解我们通过 tool -&gt; Analyze Xdebug profiler Snapshot 打开性能分析文件 cachegrind.out. 打头的文件。就会进入以下界面 了解各个选项的意思 Refresh - 刷新 Execution statistics - 执行统计数据 Call Trees - 哪个函数调用哪个函数 Callable - 已执行的文件 Own Time - 函数执行自己的代码所花费的时间(不包括对其他函数的调用) Calls - 调用次数 Callees - 调用哪些函数 Callers - 从函数被调用的地方 time 前的数字代表的是什么意思 time 列里有 数字和百分比。分别代表 执行时间和执行占用总时间百分比 单位是 server 旁边的 time 那里进行设置.默认是 ms callees 里的方法大部分都会出来一个折叠的图标，有什么用 这个可以让我们查看他的上一步执行了以什么操作。这个可以方便我们在了解调用到这个函数的过程。 找到我们关心的数据 那些地方占用的执行时间最多，为什么 我们可以在 Execution statistics 标签里对 own time 进行排序取执行占用最多的内容。里面会包含文件和函数以及方法。如果我们设置了 server 关联当前的项目，统计里的方法是可以进行跳转到项目的实际代码里。 我们通过 Callees 标签查看函数里那些方法调用耗时最多 那些方法调用最多次，在那些地方调用的比较多 Execution statistics 标签里对 calls 进行排序取执行次数最多的函数或方法。 可通过下面的 Callers 查看那些地方对他进行了调用 系列文章 xdebug的安装配置 xdebug的实际运用 xdebug性能分析 [本篇] FQA为什么要设置 xdebug.profiler_output_name 默认的不就可以了吗？如果你的项目不是多入口的类型，你保存的到一个文件就会出现性能分析文件不精确的情况。而我在上文中用的是 $_SERVER[‘REQUEST_URI’] 作为文件后缀。可以很好的区分性能分析文件。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>xdebug</tag>
        <tag>phpstorm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网站安全配置（响应头篇）]]></title>
    <url>%2F%E5%AE%89%E5%85%A8%2Fhttp-header%2F</url>
    <content type="text"><![CDATA[默认的网站环境中。有很多暴露环境信息的地方。 在 HTTP 响应头中 Server 参数会把 http 服务器的类型和版本信息完整的返回. apache 就更过分了. php 版本也会显示出来 Set-Cookie 参数关联后台的服务器的 session 默认会使用 PHPSESSID X-Powered-By 参数会返回当前环境所使用的语言以及版本信息。 那要怎么办呢. 虽然在我看来并没有什么意义. 但是黑客大佬们可不会那么想. 多暴露一些信息就会多一些安全隐患. 话不多说. 以下是解决一些方法. 网上的很多比我写还好的. 如有雷同. 勿喷 接下来我会以下面两套环境来进行处理. apache + php nginx + php 处理的方式 伪造成其他同类产品的默认响应头。 彻底隐藏 先说下 apache 的环境吧 apache 是把 php 当成自己的一个模块运行的. 所以它才会知道 php 是什么版本.在网上我找了很多资料, 都说想响应头中的 server 不能隐藏起来（你要知道和我说下哟）. 最少也会留个服务器类型. 下面我要做的就是把他能隐藏的信息隐藏起来 12ServerTokensServerSignature 在 apache.conf 中找到了这两个配置值. windows 里的为什么找不到阿. 那是因为他在 apache/conf/extra/httpd-default.conf 中 注意咯: 这里改了还要看下. apache/conf/httpd.conf 里有没有把这个文件引入. 可以在 httpd.conf 中搜索 httpd-default.conf 如果前面有 # 注释就去除. 你找到了这两参数了你不说怎么设置吗? 网上的文章和我配置里的配置参数不一样. 不要问我是怎么知道的. 我也是看这个参数上在写的注释里得知的. 123456789## ServerTokens# This directive configures what you return as the Server HTTP response# Header. The default is &apos;Full&apos; which sends information about the OS-Type# and compiled in modules.# Set to one of: Full | OS | Minor | Minimal | Major | Prod# where Full conveys the most information, and Prod the least.# 看到用 | 隔开的了吗? 那就是参数. 如果你英文好. 那你一定知道是这些参数代表着什么. 英文不好. 赶紧翻译去. 哦, 对了. 是翻译你自己的不是翻译我的(笑) 我设置的是 Prod(产品). 想深入研究也可以把参数每个配置一遍看看 ServerSignature 参数也一样. 进行设置.(记得看注释哦) 配置完了. 重启 apache. 看看对比对比有没有变化. nginx主要也是隐藏自身的版本号. 参数server_tokens off; 这个参数只用设置到 http{} 里面就可以了 phpphp 里可以控制显示 X-Powered-By 和 Set-Cookie 里的信息. 主要配置参数都在 php.ini 中的 session.name 控制 Set-Cookie 里的一个 key 相信你看到了熟悉的 PHPSESSID , laravel 框架默认使用 laravel_session expose_php 控制着 X-Powered-By 的输出. 我们关掉就可以了 其他如果你使用的是空间. 使用php 函数 ini_set 进行设置123ini_set('session.name', 'newvalue');header_remove('x-powered-by'); // php 5.3+header('x-powered-by:'); // 通用兼容方法,不过响应头会输出空的 x-powered-by 注意: 如果你网站是放在空间里运行的话. 空间默认是会帮你进行一些安全处理的. 先查看它的显示方式再进行修改. 要不然会出现一些可笑的现象.如: 请求头中出现了两个 X-Powered-By 有些框架默认会使用 php 函数设置这些配置. 如 ThinkPHP(X-Powered-By), laravel(set-cookie) 误区 php ini_set() 可以设置 expose_php 配置. 在设置系统参数之前请查看清楚文档的介绍. 网上很多都写了用 ini_set() 可以设置 expose_post 的配置. 事实上只有 php.ini 可以进行设置 了解更多: http://php.net/manual/zh/ini.list.php http://php.net/manual/zh/configuration.changes.modes.php 总结 要想让项目尽量的安全, 要注意安全方面的事情要从细节抓起. 配置里有很多你没有想到的功能. 不一定要碰到了才去处理. 粗略看一遍也会对了解系统有很大的帮助]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 的使用技巧1-环境的使用]]></title>
    <url>%2F%E5%B7%A5%E5%85%B7%2Fgit-skill-1%2F</url>
    <content type="text"><![CDATA[1、git 与subversion(svn) 的区别 分布式(git)与集中式(svn)的区别！ 集中式的版本控制代码是统一管理的。如果远程库的服务器出问题了会受影响。大多数操作都需要有网络的支持！提交、 更新和查看日志缓慢。 分布式是每一台电脑里都是完整的代码，就算是没有网络的环境也可以正常的做提交和修改处理。所有提交日志都存在本地。可以想象查看速度有多快！到有网络的环境再进行上传。而且当其他人的电脑出问题了也只是丢失他个人的距离上一次提交到网络上的代码和记录！相对于集中式觉得分布式的十分占优。 下面说说 Git 用户环境的搭建 2、Github 安装 Github 的安装的方式有两种，分别是官网的网络安装和非官网的离线安装。 在中国使用官网的网络安装简直龟速，而且容易安装失败。所以我推荐离线安装。 下载页面：http://www.pc6.com/softview/SoftView_415864.html 相信很多人都觉得这种网站太坑爹了。因为每次安装完桌子上就一堆垃圾软件，其实只要不用 高速下载器地址 里的下载就可以直接下载自己想要的压缩包了。当然下载了也没有关系，安装的时候窗口里的每一个角落都看下。有没有东西是被勾上的，把那些没有必要的勾去掉就可以了。 3、Atom 的安装 Atom 也是github 开发的一个工具. 虽然之前并不是很好用, 但是现在好用很多了. 安装包可以在官网中获得. 如果普通下载太慢. 可以使用迅雷来提高下载速度. 也可以到网上下载绿化包. 4、技巧说明 为什么要在这里讲 github desktop 和 atom 呢. 其实这些都是为了辅助 git 的用户使用. 先说说 github desktop 。个人觉得界面做的很好，方便查看本地项目的提交和代码的修改。里面还自带了 git 。可以省去安装 git 这一步。更重要的是它不但可以提交本地提交到 github 远程仓库中，还可以提交到个人的远程仓库中！只要你使用 git 命令给它添加远程仓库就可以了。 git remote add [远程仓库地址] atom 是一个代码编辑器。它的优点就是：你加载了 git 控制的项目他就会把当前项目每一个修改文件以及文件的修改行添加行给你全部显示出来。还可以在编辑器安装一些插件，喜欢用 vim 模式的同学也可以很好的使用它。还有一些 sublime text 里好用插件也可以进行安装，如 emmet 等等。相对于其他的版本控制软件。git 已经是用户体验极好的控制软件了 这样可以不使用命令行都可以进行工作了。(你要是想装逼我也不拦你 [滑稽] ) 5、相关帮助资料 ProGit 第二版 简体中文 (PDF 电子文档) http://git.oschina.net/progit/ 重点是2.Git 基础 这一章看完基础命令操作就已经学全了 Atom 文档 (在线文档) http://wiki.jikexueyuan.com/project/atom/overview.html 这文档做的很全！虽然我不是看这里学的，但是文章差不多的。：） Github desktop (视频) http://www.imooc.com/video/7625 只看看这一个视频就可以了. 如果有兴趣的话可以把这个课程看完! 下期预告 这一期只是简单的说了下 git 的好用的地方。没有什么干货，文化水平不高文笔只能写到这种程度。之后我会写 Atom 编辑器和 Github Desktop 的一些配置和使用小技巧。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冒泡排序法理解]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2Fbubble-sort%2F</url>
    <content type="text"><![CDATA[核心技术: 值对换, 多重循环 说明: 循环比对值的大小, 如果第一个值比第二个值大就进行对换.第一次循环得到第一大的值每二次循环得到第二大的值…直到只剩一个值后结束循环 注意点: 这里使用了递增递减两种循环. 所以对循环的掌握要求比较高. 要不然很容易出现排序完成后 数组出现一个多余的 空值. 12345678910111213141516171819202122&lt;?php$arr = array(5,2,7,9,10,3);function mp($arr) &#123; $count = count($arr) - 1; // 5 因为下面第二个循环中的对比值 // 因为第一次循环会得到最大的值, 第二次就得到第二个最大值. 所以使用 递减的方法. for ($i = $count; $i &gt; 0; $i--) &#123; for ($j = 0; $j &lt; $i; $j++) &#123; // 前后对比对换 if ($arr[$j] &gt; $arr[($j+1)]) &#123; $big = $arr[$j]; $arr[$j] = $arr[($j+1)]; $arr[($j+1)] = $big; &#125; &#125; &#125;&#125;$arr = mp($arr);print_r($arr);]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序法理解]]></title>
    <url>%2F%E7%AE%97%E6%B3%95%2Fquicksort%2F</url>
    <content type="text"><![CDATA[核心技术: 递归, 数组合并, 引用 说明: 取排序中的一个数字. 对剩下的数字进行排序. 得到比这个数字 (中间值) 大的和小的两个数组. 再对这两个数组进行递归处理. 注意点: 因为是递归所以需要递归点. 不然会出现死循环的情况. 这个递归点是: 对比数组长度小于等于 1的时候就直接返回 12345678910111213141516171819202122232425262728293031&lt;?php$arr = array(5,2,7,9,10,3);function kp(&amp;$arr) &#123; // 这里的引用很重要, 因为递归中会有没有返回值的情况.所以需要引用 $count = count($arr); if ($count &gt; 1) &#123; // 递归点 $median = $arr[0]; // 中间对比值 $min = array(); $max = array(); // 对比 for ($i = 1; $i &lt; $count; $i++) &#123; // 注: 这里的是从数组 1 开始. 因为数组 0 被拿去当中间对比值了 if ($arr[$i] &lt;= $median) &#123; // 这里使用小于等于是为了防止相等的值会出现问题 $min[] =&amp; $arr[$i]; // 这里使用[引用赋值]节省内存空间 &#125; else &#123; $max[] =&amp; $arr[$i]; &#125; &#125; $min = kp($min); // 只有递归到 return $arr 这一步才会得这一段的结果 $max = kp($max); // 返回排序结果 return array_merge($min, array($median), $max); &#125; else &#123; return $arr; &#125; &#125;$arr = kp($arr);print_r($arr);]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
</search>
